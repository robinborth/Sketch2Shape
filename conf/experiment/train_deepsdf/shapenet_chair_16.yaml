# @package _global_

defaults:
  - override /data: train_deepsdf
  - override /dataset: shapenet_chair_16
  - override /logger: wandb

tags: ["train_deepsdf", "overfit_16"]

model:
  decoder_scheduler:
    _partial_: True
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 100 
    gamma: 0.99
  latents_scheduler:
    _partial_: True
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 100 
    gamma: 0.99

trainer:
  max_epochs: 1000

data:
  batch_size: 4
  num_workers: 7
  chunk_size: 16384
  half: False
  
callbacks:
  early_stopping:
    patience: 1000
