# @package _global_

defaults:
  - override /data: train_deepsdf
  - override /dataset: shapenet_chair_4096
  - override /logger: wandb

tags: ["train_deepsdf", "shapenet_chair_4096"]

model:
  decoder_lr: 32e-05 # num batch size * 1e-05; see curriculum deepsdf
  adaptive_sample_strategy: True
  adaptive_mining_strategy: True
  reg_loss: True
  scheduler:
    _target_: torch.optim.lr_scheduler.StepLR
    _partial_: True
    step_size: 500
    gamma: 0.5

trainer:
  max_epochs: 2000
  precision: 16-mixed

data:
  batch_size: 32
  num_workers: 7
  chunk_size: 16384
  half: True

callbacks:
  early_stopping:
    patience: 2000
  model_checkpoint:
    save_top_k: -1
    every_n_epochs: 100
    save_last: True
