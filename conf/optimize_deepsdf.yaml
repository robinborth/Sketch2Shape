# @package _global_

defaults:
  - data:
    - optimize_latent 
  - model: optimize_latent
  - trainer: default
  - logger: default
  - hydra: default
  - paths: default
  - debug: null
  - optional local: default
  - _self_

seed: 123
task_name: optimize_deepsdf
tags: ["optimize_deepsdf"]
split: val  # train, val, test
obj_ids: ???  # overrids the split setting, make sure that obj_ids are only from the same split.
train: True
prior_idx: mean  # random(-2), mean(-1), prior, prior(idx)
eval: True
save_mesh: True  # only if eval == True
create_video: True 
ckpt_path: ???

trainer:
  num_sanity_val_steps: 0
  max_epochs: 1000 

data:
  train_dataset:
    _target_: lib.data.deepsdf_dataset.DeepSDFLatentOptimizerDataset
    chunk_size: 250000 
    half: True

model:
  _target_: lib.models.optimize_deepsdf.DeepSDFLatentOptimizer
  reg_weight: 1e-04
  video_capture_rate: 30
  loss:
    _target_: torch.nn.L1Loss
    _partial_: true
    reduction: mean
  optimizer:
    lr: 1e-03
  scheduler:
    step_size: 50 
    gamma: 0.9
  
callbacks:
  early_stopping:
    patience: 200