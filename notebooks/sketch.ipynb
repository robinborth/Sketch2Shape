{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.data.metainfo import MetaInfo\n",
    "\n",
    "def plot_images(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image.permute(1, 2, 0).detach().cpu().numpy())\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images.permute(1, 2, 0).detach().cpu().numpy())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Sketch Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ToSketch(object):\n",
    "    \"\"\"Convert the image to an edge map.\n",
    "\n",
    "    The input of the edge maps needs to be of dim 3xHxW and the output\n",
    "    \"\"\"\n",
    "\n",
    "    t_lower: int = 100\n",
    "    t_upper: int = 150\n",
    "    aperture_size: int = 3  # 3, 5, 7\n",
    "    l2_gradient: bool = True\n",
    "\n",
    "    def __call__(self, image):\n",
    "        edge = cv.Canny(\n",
    "            image,\n",
    "            threshold1=self.t_lower,\n",
    "            threshold2=self.t_upper,\n",
    "            apertureSize=self.aperture_size,\n",
    "            L2gradient=self.l2_gradient,\n",
    "        )\n",
    "        edge = cv.bitwise_not(edge)\n",
    "        return np.stack((np.stack(edge),) * 3, axis=-1)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SketchDilation(object):\n",
    "    def __init__(self, kernal_size: int = 1):\n",
    "        assert kernal_size >= 1\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=3,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"same\",\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.conv.weight = torch.nn.Parameter(torch.ones_like(self.conv.weight))\n",
    "        self.padding = (kernal_size - 1) * 2\n",
    "\n",
    "    def __call__(self, image):\n",
    "        _, H, W = image.shape\n",
    "        img = 1.0 - image\n",
    "        img = v2.functional.pad(img, padding=self.padding) # 3xH+PxW+P\n",
    "        img = self.conv(img)\n",
    "        img = 1.0 - torch.min(img, torch.tensor(1.0))\n",
    "        return v2.functional.resize(img, (H, W), antialias=True)\n",
    "\n",
    "for obj_id in range(74, 120):\n",
    "    # obj_id = 74\n",
    "    metainfo = MetaInfo(data_dir=\"/home/borth/sketch2shape/data/shapenet_chair_4096\")\n",
    "    sketch = metainfo.load_sketch(metainfo.obj_ids[obj_id], \"00011\")\n",
    "    base_transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n",
    "\n",
    "    images = []\n",
    "    for kernel_size in range(1, 10, 2):\n",
    "        dilation = SketchDilation(kernal_size=kernel_size)\n",
    "        image = dilation(base_transform(sketch))\n",
    "        images.append(image)\n",
    "\n",
    "    plot_images(images, size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ToSilhouette(object):\n",
    "    def __call__(self, image):\n",
    "        surface_maks = image.sum(0) < 2.95\n",
    "        image[:, surface_maks] = 0.0\n",
    "        return image\n",
    "\n",
    "@dataclass\n",
    "class ToGrayScale(object):\n",
    "    def __call__(self, image):\n",
    "        mean = image.mean(0)\n",
    "        return torch.stack([mean, mean, mean], dim=0)\n",
    "\n",
    "grayscale = ToGrayScale()\n",
    "normal = metainfo.load_normal(metainfo.obj_ids[obj_id], \"00011\")\n",
    "image = grayscale(jitter(base_transform(normal)))\n",
    "# image = grayscale(base_transform(normal))\n",
    "plot_images(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack multiple sketches on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 4\n",
    "overlaps = []\n",
    "for degree, image in enumerate(images[1:4][::-1]):\n",
    "    img = 1 - image\n",
    "    overlaps.append(v2.functional.rotate(img, degree))\n",
    "plot_images(1 - torch.stack(overlaps).sum(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpness_images = [\n",
    "    v2.functional.adjust_sharpness(images[0], 0),\n",
    "    v2.functional.adjust_sharpness(images[0], 100),\n",
    "]\n",
    "plot_images(sharpness_images, size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image = v2.functional.resize(images[4], size=(64, 64), antialias=True)\n",
    "plot_images(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_img = v2.functional.pad(images[5], padding=5, fill=1.0)\n",
    "plot_images(pad_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch2shape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
