{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frechet Inception Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data.metainfo import MetaInfo\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "import numpy as np\n",
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.data.transforms import BaseTransform\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "import cv2 as cv\n",
    "from torchvision.transforms import v2\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from lib.data.transforms import ToSketch, DilateSketch, ToSilhouette, ToGrayScale\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "\n",
    "\n",
    "def transform(normal):\n",
    "    _transform = BaseTransform()\n",
    "    return _transform(normal).to(\"cuda\")\n",
    "\n",
    "\n",
    "def plot_images(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image)\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "obj_id = 0\n",
    "metainfo = MetaInfo(data_dir=\"/home/borth/sketch2shape/data/shapenet_chair_4096\")\n",
    "cfg = load_config(\"optimize_sketch\", [\"+dataset=shapenet_chair_4096\"])\n",
    "metainfo = MetaInfo(cfg.data.data_dir)\n",
    "cfg.model.prior_obj_id = metainfo.obj_ids[obj_id]\n",
    "model = hydra.utils.instantiate(cfg.model).to(\"cuda\")\n",
    "label = metainfo.obj_id_to_label(metainfo.obj_ids[0])\n",
    "model.latent = model.deepsdf.lat_vecs.weight[label]\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "plot_images(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = BaseTransform(normalize=False)\n",
    "to_sketch = ToSketch()\n",
    "fid = FrechetInceptionDistance(feature=2048, normalize=True)\n",
    "\n",
    "for obj_id in metainfo.obj_ids[:10]:\n",
    "    img = transform(metainfo.load_sketch(obj_id, \"00011\"))\n",
    "    fid.update(img[None, ...], real=True)\n",
    "\n",
    "for obj_id in metainfo.obj_ids[:10]:\n",
    "    label = metainfo.obj_id_to_label(metainfo.obj_ids[0])\n",
    "    model.latent = model.deepsdf.lat_vecs.weight[label]\n",
    "    img = model.capture_camera_frame().permute(2, 0, 1).detach().cpu()\n",
    "    img = to_sketch(img)\n",
    "    fid.update(img[None, ...], real=False)\n",
    "\n",
    "fid.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        ToSketch(),\n",
    "        v2.RandomRotation(5),\n",
    "        DilateSketch(kernel_size=1),\n",
    "    ]\n",
    ")\n",
    "t = 0\n",
    "n = 256 \n",
    "for i in range(n):\n",
    "    s = time.time()\n",
    "    normal = metainfo.load_normal(metainfo.obj_ids[i], \"00011\")\n",
    "    sketch = transforms(normal).permute(1, 2, 0)\n",
    "    t += time.time() - s\n",
    "1 / (t / 7)\n",
    "plot_images(sketch.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal To Sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        ToSketch(),\n",
    "        v2.RandomRotation(5, fill=1.0),\n",
    "        DilateSketch(kernel_size=2),\n",
    "    ]\n",
    ")\n",
    "normal = metainfo.load_normal(metainfo.obj_ids[0], \"00011\")\n",
    "sketch = transforms(normal).permute(1, 2, 0)\n",
    "plot_images(sketch.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.84614562988281"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.eval.clip_score import CLIPScore\n",
    "from lib.data.metainfo import MetaInfo\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "import numpy as np\n",
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.data.transforms import BaseTransform\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "import cv2 as cv\n",
    "from torchvision.transforms import v2\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from lib.data.transforms import ToSketch, DilateSketch, ToSilhouette, ToGrayScale\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metainfo = MetaInfo(data_dir=\"/home/borth/sketch2shape/data/shapenet_chair_4096\")\n",
    "cfg = load_config(\"optimize_sketch\", [\"+dataset=shapenet_chair_4096\"])\n",
    "metainfo = MetaInfo(cfg.data.data_dir)\n",
    "cfg.model.prior_obj_id = metainfo.obj_ids[0]\n",
    "model = hydra.utils.instantiate(cfg.model).to(\"cuda\")\n",
    "\n",
    "obj_id = metainfo.obj_ids[0]\n",
    "transform = BaseTransform(normalize=False)\n",
    "to_sketch = ToSketch()\n",
    "# gt sketch\n",
    "gt_sketch = metainfo.load_sketch(obj_id, \"00011\")\n",
    "gt_sketch = transform(gt_sketch)[None, ...]\n",
    "# rendered sketch\n",
    "model.latent = model.deepsdf.lat_vecs.weight[0]\n",
    "rendered_normal = model.capture_camera_frame().permute(2, 0, 1)\n",
    "rendered_sketch = to_sketch(rendered_normal.detach().cpu())[None, ...]\n",
    "clip = CLIPScore()\n",
    "clip.update(gt_sketch, rendered_sketch)\n",
    "clip.update(gt_sketch, rendered_sketch)\n",
    "clip.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch2shape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
