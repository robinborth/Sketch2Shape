{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.transforms import v2\n",
    "from lib.utils.config import load_config\n",
    "from lib.data.metainfo import MetaInfo\n",
    "import hydra\n",
    "import glob\n",
    "import cv2\n",
    "import tqdm\n",
    "\n",
    "from lib.utils.config import load_config\n",
    "from lib.data.metainfo import MetaInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture all .mov videos in raw_video directory\n",
    "demo_folder = \"/home/korth/sketch2shape/demo_video\"\n",
    "video_name = \"five\"\n",
    "video_paths = glob.glob(f\"{demo_folder}/input_videos/{video_name}*\")\n",
    "frames_folder = f\"{demo_folder}/video_frames\"\n",
    "\n",
    "\n",
    "# create folders if they do not exist\n",
    "if not os.path.exists(frames_folder):\n",
    "    os.makedirs(frames_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Frames from Raw Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "num_frames_to_extract = 150  # Set the number of frames to extract\n",
    "for video_file in video_paths:\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    # Get the total number of frames in the video\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate the frame interval\n",
    "    frame_interval = max(total_frames // num_frames_to_extract, 1)\n",
    "    \n",
    "    # Read frames at the specified interval\n",
    "    frame_count = 0\n",
    "    while video.isOpened() and frame_count < total_frames:\n",
    "        # Read the current frame\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        # If the frame was read successfully\n",
    "        if ret:\n",
    "            # Add the frame to the list of frames\n",
    "            if frame_count % frame_interval == 0:\n",
    "                frames.append(frame)\n",
    "            frame_count += 1\n",
    "        else:\n",
    "            # Break the loop if the video is completed\n",
    "            break\n",
    "    \n",
    "    # Release the video file\n",
    "    video.release()\n",
    "\n",
    "print(f\"Extracted {len(frames)} frames from {len(video_files)} videos\")\n",
    "\n",
    "folder = f\"{frames_folder}/{video_name}\"\n",
    "# create folder if it does not exist (in python)\n",
    "os.makedirs(frames_folder, exist_ok=True)\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# save the frames to disk\n",
    "for i, frame in enumerate(frames):\n",
    "    cv2.imwrite(f\"{folder}/frame_{i:03}.png\", frame)\n",
    "\n",
    "print(f\"Saved {len(frames)} frames to disk at '{folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"optimize_sketch\", [\"dataset=shapenet_chair_single_view_4096\"])\n",
    "metainfo = MetaInfo(cfg.data.data_dir)\n",
    "\n",
    "cfg.model.prior_obj_id = metainfo.obj_ids[4015]\n",
    "cfg.model.loss_ckpt_path = \"/home/borth/sketch2shape/checkpoints/latent_siamese_sketch_grayscale_latent_256.ckpt\"\n",
    "cfg.model.latent_init = \"retrieval\"\n",
    "cfg.model.retrieval_k = 4\n",
    "model = hydra.utils.instantiate(cfg.model).to(\"cuda\")\n",
    "\n",
    "model.deepsdf.create_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.Resize((256, 256)),\n",
    "    # v2.CenterCrop(256),\n",
    "    v2.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "def load_handrawn(img_path):\n",
    "    # load img, convert to torch tensor and resize to 256x256\n",
    "    img1 = plt.imread(img_path)\n",
    "    img1 = img1 / 255.0\n",
    "\n",
    "    return transform(img1).to(torch.float32)\n",
    "\n",
    "def load_sketch(img_path):\n",
    "    # load img, convert to torch tensor and resize to 256x256\n",
    "    img1 = plt.imread(img_path)\n",
    "    return transform(img1).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each frame and extract normals by rendering the latents\n",
    "visualize = False\n",
    "\n",
    "original_images = []\n",
    "normal_images = []\n",
    "\n",
    "for path in tqdm.tqdm(sorted(glob.glob(frames_folder + \"/\" + video_name + \"/*.png\"))):\n",
    "    if \"handrawn\" in path:\n",
    "        img = load_handrawn(path)\n",
    "    else:\n",
    "        img = load_sketch(path)\n",
    "    with torch.no_grad():\n",
    "        latent = model.loss(img.unsqueeze(0).cuda())\n",
    "        normals = model.deepsdf.capture_camera_frame(latent.squeeze())\n",
    "    \n",
    "    # Save original and normal images into separate lists\n",
    "    original_images.append(plt.imread(path))\n",
    "    normal_images.append(normals.cpu().numpy())\n",
    "    \n",
    "    if visualize:\n",
    "        # Print original image, preprocessed image, and normals\n",
    "        plt.figure()\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(\"Original\")\n",
    "        plt.imshow(plt.imread(path))\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(\"Preprocessed\")\n",
    "        plt.imshow(img.cpu().numpy().transpose(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"Normals\")\n",
    "        plt.imshow(normals.cpu().numpy())\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize for sanity check\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(plt.imread(path))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Preprocessed\")\n",
    "plt.imshow(img.cpu().numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Normals\")\n",
    "plt.imshow(normals.cpu().numpy())\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# if output_videos folder does not exist, make it\n",
    "if not os.path.exists(f\"{demo_folder}/output_videos\"):\n",
    "    os.makedirs(f\"{demo_folder}/output_videos\")\n",
    "\n",
    "# Define the output video filenames\n",
    "original_video_filename = f\"{demo_folder}/output_videos/{video_name}_original_video.mp4\"\n",
    "normal_video_filename = f\"{demo_folder}/output_videos/{video_name}_normal_video.mp4\"\n",
    "\n",
    "# Define the video codec and frame rate\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "fps = 10\n",
    "\n",
    "res_original = original_images[0].shape[0]\n",
    "\n",
    "# Create the video writers\n",
    "original_video_writer = cv2.VideoWriter(original_video_filename, fourcc, fps, (res_original, res_original))\n",
    "normal_video_writer = cv2.VideoWriter(normal_video_filename, fourcc, fps, (256, 256))\n",
    "\n",
    "# Write the frames to the videos\n",
    "for idx, frame in enumerate(original_images):\n",
    "    original_video_writer.write((frame*255).astype(np.uint8))\n",
    "\n",
    "for frame in normal_images:\n",
    "    normal_video_writer.write((frame*255).astype(np.uint8))\n",
    "\n",
    "# Release the video writers\n",
    "original_video_writer.release()\n",
    "normal_video_writer.release()\n",
    "\n",
    "print(\"Videos created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Side by Side Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output video filename\n",
    "side_by_side_video_filename = f\"{demo_folder}/output_videos/{video_name}_side_by_side_video.mp4\"\n",
    "\n",
    "# Create the video writer\n",
    "side_by_side_video_writer = cv2.VideoWriter(side_by_side_video_filename, fourcc, 5, (392, 196))\n",
    "\n",
    "# Write the frames to the video\n",
    "for idx, (original_frame, normal_frame) in enumerate(zip(original_images, normal_images)):\n",
    "    # Resize the frames to have the same height\n",
    "    original_frame_resized = cv2.resize(original_frame, (196, 196))\n",
    "    normal_frame_resized = cv2.resize(normal_frame, (196, 196))\n",
    "    \n",
    "    # Concatenate the frames side by side\n",
    "    side_by_side_frame = cv2.hconcat([original_frame_resized, normal_frame_resized])\n",
    "    \n",
    "    # Write the side by side frame to the video\n",
    "    side_by_side_video_writer.write((side_by_side_frame*255).astype(np.uint8))\n",
    "\n",
    "# Release the video writer\n",
    "side_by_side_video_writer.release()\n",
    "\n",
    "print(\"Side by side video created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch2shape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
