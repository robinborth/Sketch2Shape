{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'lib.optimizer.sketch.SketchOptimizer':\nAttributeError(\"'SketchOptimizer' object has no attribute 'sketch_transform'\")\nfull_key: model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/sketch2shape/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_target_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/sketch2shape/lib/optimizer/sketch.py:14\u001b[0m, in \u001b[0;36mSketchOptimizer.__init__\u001b[0;34m(self, loss_weight, silhouette_loss, silhouette_weight, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      9\u001b[0m     loss_weight: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     13\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sketch2shape/lib/optimizer/latent.py:86\u001b[0m, in \u001b[0;36mLatentOptimizer.__init__\u001b[0;34m(self, data_dir, loss_ckpt_path, deepsdf_ckpt_path, optimizer, scheduler, latent_init, sketch_mode, retrieval_mode, reg_loss, reg_weight, prior_obj_id, prior_view_id, retrieval_k, mesh_resolution, mesh_chunk_size, n_render_steps, clamp_sdf, step_scale, surface_eps, sphere_eps, normal_eps, log_images, capture_rate, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_retrieval_latents(\n\u001b[1;32m     80\u001b[0m         obj_id\u001b[38;5;241m=\u001b[39mprior_obj_id,\n\u001b[1;32m     81\u001b[0m         view_id\u001b[38;5;241m=\u001b[39mprior_view_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m         k\u001b[38;5;241m=\u001b[39mretrieval_k,\n\u001b[1;32m     85\u001b[0m     )\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_latent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior_obj_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43msketch_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msketch_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sketch2shape/lib/optimizer/latent.py:134\u001b[0m, in \u001b[0;36mLatentOptimizer.init_latent\u001b[0;34m(self, latent_init, obj_id, name, sketch_mode)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_latent\u001b[39m(\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    129\u001b[0m     latent_init: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m     sketch_mode: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    133\u001b[0m ):\n\u001b[0;32m--> 134\u001b[0m     latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(name, latent)\n",
      "File \u001b[0;32m~/sketch2shape/lib/optimizer/latent.py:116\u001b[0m, in \u001b[0;36mLatentOptimizer.get_latent\u001b[0;34m(self, latent_init, obj_id, sketch_mode)\u001b[0m\n\u001b[1;32m    115\u001b[0m sketch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetainfo\u001b[38;5;241m.\u001b[39mload_image(label, view_id, sketch_mode)  \u001b[38;5;66;03m# sketch\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m loss_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msketch_transform\u001b[49m(sketch)[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39membedding(loss_input)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/sketch2shape/lib/python3.11/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SketchOptimizer' object has no attribute 'sketch_transform'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m cfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlatent_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatent\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m cfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mretrieval_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m---> 49\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mhydra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sketch2shape/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     _convert_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mCONVERT, ConvertMode\u001b[38;5;241m.\u001b[39mNONE)\n\u001b[1;32m    224\u001b[0m     _partial_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mPARTIAL, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_convert_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_partial_\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m OmegaConf\u001b[38;5;241m.\u001b[39mis_list(config):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     config_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/miniconda3/envs/sketch2shape/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 value \u001b[38;5;241m=\u001b[39m instantiate_node(\n\u001b[1;32m    343\u001b[0m                     value, convert\u001b[38;5;241m=\u001b[39mconvert, recursive\u001b[38;5;241m=\u001b[39mrecursive\n\u001b[1;32m    344\u001b[0m                 )\n\u001b[1;32m    345\u001b[0m             kwargs[key] \u001b[38;5;241m=\u001b[39m _convert_node(value, convert)\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_target_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;66;03m# instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert \u001b[38;5;241m==\u001b[39m ConvertMode\u001b[38;5;241m.\u001b[39mALL \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    352\u001b[0m         convert \u001b[38;5;129;01min\u001b[39;00m (ConvertMode\u001b[38;5;241m.\u001b[39mPARTIAL, ConvertMode\u001b[38;5;241m.\u001b[39mOBJECT)\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mobject_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    354\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda3/envs/sketch2shape/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_key:\n\u001b[1;32m     96\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfull_key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Error in call to target 'lib.optimizer.sketch.SketchOptimizer':\nAttributeError(\"'SketchOptimizer' object has no attribute 'sketch_transform'\")\nfull_key: model"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.data.transforms import BaseTransform\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from lib.visualize.image import image_grid\n",
    "from torch.nn.functional import l1_loss\n",
    "import cv2 as cv\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "def transform(normal):\n",
    "    _transform = BaseTransform()\n",
    "    return _transform(normal).to(\"cuda\")\n",
    "\n",
    "def plot_images_np(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image)\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images)\n",
    "        plt.show()\n",
    "\n",
    "def plot_images(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image.permute(1, 2, 0).detach().cpu().numpy())\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images.permute(1, 2, 0).detach().cpu().numpy())\n",
    "        plt.show()\n",
    "\n",
    "cfg = load_config(\"optimize_sketch\", [\"+dataset=shapenet_chair_4096\"])\n",
    "metainfo = MetaInfo(cfg.data.data_dir)\n",
    "\n",
    "cfg.model.prior_obj_id = metainfo.obj_ids[0]\n",
    "cfg.model.loss_ckpt_path = \"/home/borth/sketch2shape/checkpoints/latent_siamese_sketch_grayscale_multi_view_256.ckpt\"\n",
    "cfg.model.latent_init = \"latent\"\n",
    "cfg.model.retrieval_k = 4\n",
    "model = hydra.utils.instantiate(cfg.model).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data.transforms import BaseTransform\n",
    "from lib.render.camera import Camera\n",
    "from lib.render.mesh import normal_to_grayscale\n",
    "\n",
    "view_id = 0\n",
    "transform = BaseTransform(to_image=True, normalize=False)\n",
    "def normals_to_grayscales(\n",
    "    normals: np.ndarray,\n",
    "    azims: list = [],\n",
    "    elevs: list = [],\n",
    "):\n",
    "    grayscales = []\n",
    "    view_id = 0\n",
    "    for azim in azims:\n",
    "        for elev in elevs:\n",
    "            camera_position = Camera(azim=azim, elev=elev).camera_position()\n",
    "            grayscale = normal_to_grayscale(normals[0], camera_position)\n",
    "            grayscales.append(grayscale)\n",
    "            view_id += 1\n",
    "    return np.stack(grayscales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_id = 0\n",
    "obj_id = metainfo.obj_ids[0]\n",
    "for view_id, camera_position in tqdm(enumerate(camera_positions), total=len(camera_positions)):\n",
    "    normal = transform(metainfo.load_normal(obj_id, f\"{view_id:05}\")).to(\"cuda\")\n",
    "    normal = normal.permute(1, 2, 0)\n",
    "    grayscale = model.deepsdf.normal_to_grayscale(normal, camera_position=camera_position)\n",
    "    view_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render Chair From the Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azim = -89\n",
    "elev = -20\n",
    "model.latent = model.deepsdf.lat_vecs.weight[0]\n",
    "model.deepsdf.create_camera(azim=azim, elev=elev)\n",
    "model.deepsdf.hparams[\"surface_eps\"] = 1e-03\n",
    "model.deepsdf.hparams[\"ambient\"] = 0.2\n",
    "model.deepsdf.hparams[\"diffuse\"] = 0.5\n",
    "rendered_normal = model.capture_camera_frame(\"grayscale\").detach().cpu().numpy()\n",
    "print(model.deepsdf.camera_position)\n",
    "plot_images_np(rendered_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phong Shader Inf Far Away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set mean and standard deviation\n",
    "mean = 0\n",
    "std_dev = 1\n",
    "\n",
    "# Generate random numbers from the Gaussian distribution\n",
    "data3 = np.random.normal(90, 22.5, 50)\n",
    "data2 = np.random.normal(45, 22.5, 50)\n",
    "data1 = np.random.normal(0, 22.5, 50)\n",
    "data4 = np.random.normal(-45, 22.5, 50)\n",
    "data5 = np.random.normal(-90, 22.5, 50)\n",
    "\n",
    "# data3 = np.random.uniform(90 - 22.5, 90 + 22.5, 50)\n",
    "# data2 = np.random.uniform(45 - 22.5, 45 + 22.5, 50)\n",
    "# data1 = np.random.uniform(0 - 22.5, 0 + 22.5, 50)\n",
    "# data4 = np.random.uniform(-90 - 22.5, -90 + 22.5, 50)\n",
    "# data5 = np.random.uniform(-45 - 22.5, -45 + 22.5, 50)\n",
    "\n",
    "data = np.concatenate([data1, data2, data3, data4, data5])\n",
    "\n",
    "# Create histogram\n",
    "plt.hist(data, bins=50, density=True, alpha=0.6, color='g')\n",
    "\n",
    "# Plot Gaussian PDF\n",
    "# xmin, xmax = plt.xlim()\n",
    "# x = np.linspace(xmin, xmax, 100)\n",
    "# p = np.exp(-0.5 * ((x - mean) / std_dev) ** 2) / (std_dev * np.sqrt(2 * np.pi))\n",
    "# plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "plt.title('Gaussian distribution with mean = {} and std = {}'.format(mean, std_dev))\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.deepsdf.create_camera(azim=-90, elev=-45)\n",
    "obj_id = 0\n",
    "light_direction = model.deepsdf.camera_position\n",
    "# light_direction = [1.0, 1.0, 1.0]\n",
    "ambient = 0.3\n",
    "diffuse = 0.5\n",
    "\n",
    "metainfo = MetaInfo(data_dir=\"/home/borth/sketch2shape/data/shapenet_chair_4096\")\n",
    "trans = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "# normal = trans(metainfo.load_normal(metainfo.obj_ids[obj_id], \"00011\"))\n",
    "# normal = trans(metainfo.load_normal(metainfo.obj_ids[obj_id], \"00081\"))\n",
    "model.latent = model.deepsdf.lat_vecs.weight[5]\n",
    "normal = trans(model.capture_camera_frame().detach().cpu().numpy())\n",
    "mask = normal.sum(0) > 2.95\n",
    "# normal[0, :, :] *= -1  # flip the shadow so that it looks from every side the same\n",
    "# normal[:, mask] = 0.0\n",
    "\n",
    "L = torch.tensor(light_direction.detach().cpu())  #  (3,)\n",
    "# L = torch.tensor(light_direction)\n",
    "L = L / torch.norm(L)\n",
    "image = torch.zeros_like(normal)\n",
    "image += ambient\n",
    "image += diffuse * (L[..., None, None] * normal).sum(0)[None, ...]\n",
    "image[:, mask] = 1\n",
    "plot_images(image, size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(L[..., None, None] * normal).sum(0)[None, ...].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Shader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id = 0\n",
    "metainfo = MetaInfo(data_dir=\"/home/borth/sketch2shape/data/shapenet_chair_4096\")\n",
    "trans = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "# normal = trans(metainfo.load_normal(metainfo.obj_ids[obj_id], \"00081\"))\n",
    "normal = trans(metainfo.load_normal(metainfo.obj_ids[obj_id], \"00011\"))\n",
    "mask = normal.sum(0) > 2.95\n",
    "# normal[2, :, :] *= -1  # flip the shadow\n",
    "normal[:, mask] = 1\n",
    "mean = normal.mean(0)\n",
    "image = torch.stack([mean, mean, mean], dim=0)\n",
    "plot_images(image, size=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch2shape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
