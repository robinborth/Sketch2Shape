{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.data.transforms import BaseTransform\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from lib.visualize.image import image_grid\n",
    "from torch.nn.functional import l1_loss\n",
    "import cv2 as cv\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "def transform(normal):\n",
    "    _transform = BaseTransform()\n",
    "    return _transform(normal).to(\"cuda\")\n",
    "\n",
    "def plot_images_np(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image)\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images)\n",
    "        plt.show()\n",
    "\n",
    "def plot_images(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image.permute(1, 2, 0).detach().cpu().numpy())\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images.permute(1, 2, 0).detach().cpu().numpy())\n",
    "        plt.show()\n",
    "\n",
    "cfg = load_config(\"optimize_sketch\", [\"+dataset=shapenet_chair_4096\"])\n",
    "metainfo = MetaInfo(cfg.data.data_dir)\n",
    "\n",
    "cfg.model.prior_obj_id = metainfo.obj_ids[0]\n",
    "cfg.model.loss_ckpt_path = \"/home/borth/sketch2shape/checkpoints/latent_siamese_sketch_grayscale_multi_view_256.ckpt\"\n",
    "cfg.model.latent_init = \"latent\"\n",
    "cfg.model.retrieval_k = 4\n",
    "model = hydra.utils.instantiate(cfg.model).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data.transforms import BaseTransform\n",
    "from lib.render.camera import Camera\n",
    "from lib.render.mesh import normal_to_grayscale\n",
    "\n",
    "view_id = 0\n",
    "transform = BaseTransform(to_image=True, normalize=False)\n",
    "def normals_to_grayscales(\n",
    "    normals: np.ndarray,\n",
    "    azims: list = [],\n",
    "    elevs: list = [],\n",
    "):\n",
    "    grayscales = []\n",
    "    view_id = 0\n",
    "    for azim in azims:\n",
    "        for elev in elevs:\n",
    "            camera_position = Camera(azim=azim, elev=elev).camera_position()\n",
    "            grayscale = normal_to_grayscale(normals[0], camera_position)\n",
    "            grayscales.append(grayscale)\n",
    "            view_id += 1\n",
    "    return np.stack(grayscales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_id = 0\n",
    "obj_id = metainfo.obj_ids[0]\n",
    "for view_id, camera_position in tqdm(enumerate(camera_positions), total=len(camera_positions)):\n",
    "    normal = transform(metainfo.load_normal(obj_id, f\"{view_id:05}\")).to(\"cuda\")\n",
    "    normal = normal.permute(1, 2, 0)\n",
    "    grayscale = model.deepsdf.normal_to_grayscale(normal, camera_position=camera_position)\n",
    "    view_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render Chair From the Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azim = -89\n",
    "elev = -20\n",
    "model.latent = model.deepsdf.lat_vecs.weight[0]\n",
    "model.deepsdf.create_camera(azim=azim, elev=elev)\n",
    "model.deepsdf.hparams[\"surface_eps\"] = 1e-03\n",
    "model.deepsdf.hparams[\"ambient\"] = 0.2\n",
    "model.deepsdf.hparams[\"diffuse\"] = 0.5\n",
    "rendered_normal = model.capture_camera_frame(\"grayscale\").detach().cpu().numpy()\n",
    "print(model.deepsdf.camera_position)\n",
    "plot_images_np(rendered_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phong Shader Inf Far Away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set mean and standard deviation\n",
    "mean = 0\n",
    "std_dev = 1\n",
    "\n",
    "# Generate random numbers from the Gaussian distribution\n",
    "data3 = np.random.normal(90, 22.5, 50)\n",
    "data2 = np.random.normal(45, 22.5, 50)\n",
    "data1 = np.random.normal(0, 22.5, 50)\n",
    "data4 = np.random.normal(-45, 22.5, 50)\n",
    "data5 = np.random.normal(-90, 22.5, 50)\n",
    "\n",
    "# data3 = np.random.uniform(90 - 22.5, 90 + 22.5, 50)\n",
    "# data2 = np.random.uniform(45 - 22.5, 45 + 22.5, 50)\n",
    "# data1 = np.random.uniform(0 - 22.5, 0 + 22.5, 50)\n",
    "# data4 = np.random.uniform(-90 - 22.5, -90 + 22.5, 50)\n",
    "# data5 = np.random.uniform(-45 - 22.5, -45 + 22.5, 50)\n",
    "\n",
    "data = np.concatenate([data1, data2, data3, data4, data5])\n",
    "\n",
    "# Create histogram\n",
    "plt.hist(data, bins=50, density=True, alpha=0.6, color='g')\n",
    "\n",
    "# Plot Gaussian PDF\n",
    "# xmin, xmax = plt.xlim()\n",
    "# x = np.linspace(xmin, xmax, 100)\n",
    "# p = np.exp(-0.5 * ((x - mean) / std_dev) ** 2) / (std_dev * np.sqrt(2 * np.pi))\n",
    "# plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "plt.title('Gaussian distribution with mean = {} and std = {}'.format(mean, std_dev))\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.deepsdf.create_camera(azim=-90, elev=-45)\n",
    "obj_id = 0\n",
    "light_direction = model.deepsdf.camera_position\n",
    "# light_direction = [1.0, 1.0, 1.0]\n",
    "ambient = 0.3\n",
    "diffuse = 0.5\n",
    "\n",
    "metainfo = MetaInfo(data_dir=\"/home/borth/sketch2shape/data/shapenet_chair_4096\")\n",
    "trans = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "# normal = trans(metainfo.load_normal(metainfo.obj_ids[obj_id], \"00011\"))\n",
    "# normal = trans(metainfo.load_normal(metainfo.obj_ids[obj_id], \"00081\"))\n",
    "model.latent = model.deepsdf.lat_vecs.weight[5]\n",
    "normal = trans(model.capture_camera_frame().detach().cpu().numpy())\n",
    "mask = normal.sum(0) > 2.95\n",
    "# normal[0, :, :] *= -1  # flip the shadow so that it looks from every side the same\n",
    "# normal[:, mask] = 0.0\n",
    "\n",
    "L = torch.tensor(light_direction.detach().cpu())  #  (3,)\n",
    "# L = torch.tensor(light_direction)\n",
    "L = L / torch.norm(L)\n",
    "image = torch.zeros_like(normal)\n",
    "image += ambient\n",
    "image += diffuse * (L[..., None, None] * normal).sum(0)[None, ...]\n",
    "image[:, mask] = 1\n",
    "plot_images(image, size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(L[..., None, None] * normal).sum(0)[None, ...].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Shader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id = 0\n",
    "metainfo = MetaInfo(data_dir=\"/home/borth/sketch2shape/data/shapenet_chair_4096\")\n",
    "trans = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "# normal = trans(metainfo.load_normal(metainfo.obj_ids[obj_id], \"00081\"))\n",
    "normal = trans(metainfo.load_normal(metainfo.obj_ids[obj_id], \"00011\"))\n",
    "mask = normal.sum(0) > 2.95\n",
    "# normal[2, :, :] *= -1  # flip the shadow\n",
    "normal[:, mask] = 1\n",
    "mean = normal.mean(0)\n",
    "image = torch.stack([mean, mean, mean], dim=0)\n",
    "plot_images(image, size=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch2shape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
