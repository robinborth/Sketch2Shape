{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.data.transforms import BaseTransform\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from lib.data.transforms import BaseTransform, DilateSketch, ToSketch\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "\n",
    "def plot_images(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image)\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "cfg = load_config(\"optimize_sketch\", [\"+dataset=shapenet_chair_4096\"])\n",
    "metainfo = MetaInfo(cfg.data.data_dir)\n",
    "\n",
    "cfg.model.prior_obj_id = metainfo.obj_ids[0]\n",
    "cfg.model.loss_ckpt_path = \"/home/borth/sketch2shape/checkpoints/latent_siamese_sketch_grayscale_latent_256.ckpt\"\n",
    "cfg.model.latent_init = \"latent\"\n",
    "\n",
    "model = hydra.utils.instantiate(cfg.model).to(\"cuda\")\n",
    "\n",
    "# transforms\n",
    "transforms = [v2.Resize((256, 256)), ToSketch(), DilateSketch(kernel_size=5)]\n",
    "trans = BaseTransform(transforms=transforms)\n",
    "to_image = BaseTransform(normalize=False, transforms=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silhouette Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10, 4112, (4117), 12, 13, 4152\n",
    "# obj_label = 4117\n",
    "# obj_label = 4152\n",
    "obj_label = 3916  # [1250,  585, 3916,  673]  4015\n",
    "min_eps = 1e-03\n",
    "max_eps = 5e-02\n",
    "azim = 40\n",
    "elev = -20\n",
    "width = 256\n",
    "height = 256\n",
    "focal = 512\n",
    "\n",
    "# get the sketch form the dataset\n",
    "img = metainfo.load_sketch(metainfo.obj_ids[obj_label], \"00011\")\n",
    "sketch = trans(img)[None, ...].to(\"cuda\")\n",
    "\n",
    "# get the rendered normal\n",
    "model.latent = model.loss.embedding(sketch, mode=\"sketch\")[0]\n",
    "model.deepsdf.hparams[\"surface_eps\"] = min_eps\n",
    "model.deepsdf.create_camera(azim=azim, elev=elev)\n",
    "model.deepsdf.eval()\n",
    "with torch.no_grad():\n",
    "    points, surface_mask = model.deepsdf.sphere_tracing(\n",
    "        latent=model.latent,\n",
    "        points=model.deepsdf.camera_points,\n",
    "        mask=model.deepsdf.camera_mask,\n",
    "        rays=model.deepsdf.camera_rays,\n",
    "    )\n",
    "    image = model.deepsdf.render_grayscale(\n",
    "        points=points,\n",
    "        latent=model.latent,\n",
    "        mask=surface_mask,\n",
    "    )\n",
    "rendered_normal = image.detach().cpu().numpy()\n",
    "sketch, normal = to_image(img).permute(1, 2, 0), rendered_normal\n",
    "\n",
    "normal_input = model.deepsdf.image_to_siamese(torch.tensor(normal).to(\"cuda\"))\n",
    "sketch_input = model.deepsdf.image_to_siamese(torch.tensor(sketch).to(\"cuda\"))\n",
    "normal_emb = model.loss.embedding(normal_input)\n",
    "sketch_emb = model.loss.embedding(sketch_input)\n",
    "loss = model.loss.compute(normal_emb, sketch_emb)\n",
    "print(loss)\n",
    "\n",
    "# silhouette information\n",
    "min_sdf = torch.abs(model.forward(points)).reshape(width, height).detach().cpu()\n",
    "min_points = points.reshape(width, height, 3).detach().cpu()\n",
    "min_normals = ((image - 0.5) / 0.5).detach().cpu()\n",
    "silhouette = ((min_sdf < max_eps) & (min_sdf > min_eps)).numpy().astype(np.uint8)\n",
    "\n",
    "\n",
    "surface_mask = (\n",
    "    surface_mask.reshape(width, height).detach().cpu().numpy().astype(np.uint8)\n",
    ")\n",
    "\n",
    "\n",
    "sil = torch.zeros_like(min_sdf)\n",
    "w2c = model.deepsdf.world_to_camera.detach().cpu().to(torch.float32)\n",
    "idx = np.where(silhouette)\n",
    "w_points = min_points[idx] - min_normals[idx] * min_sdf[idx][..., None]\n",
    "\n",
    "c_points = np.ones((w_points.shape[0], 4))\n",
    "c_points[:, :3] = w_points\n",
    "c_points = w2c @ c_points.T\n",
    "c_points = c_points.T\n",
    "\n",
    "pxs = ((width * 0.5) - (c_points[:, 0] * focal) / c_points[:, 2]).to(torch.int)\n",
    "pys = ((height * 0.5) - (c_points[:, 1] * focal) / c_points[:, 2]).to(torch.int)\n",
    "\n",
    "inside_mask = (pxs >= 0) & (pxs < width) & (pys >= 0) & (pys < height)\n",
    "pxs = pxs[inside_mask]\n",
    "pys = pys[inside_mask]\n",
    "\n",
    "unique_idx, counts = torch.stack([pys, pxs]).unique(dim=1, return_counts=True)\n",
    "sil[unique_idx[0], unique_idx[1]] = counts.to(torch.float32)\n",
    "\n",
    "blur = v2.GaussianBlur(kernel_size=5, sigma=3.0)\n",
    "sil_blur = blur(torch.stack([sil, sil, sil]))[0]\n",
    "sil_blur = torch.clip(sil_blur - 0.5, min=0)\n",
    "\n",
    "blur1 = v2.GaussianBlur(kernel_size=9, sigma=9)\n",
    "in_blur = torch.tensor(np.stack([surface_mask, surface_mask, surface_mask]), dtype=torch.float32)\n",
    "s_mask = blur1(in_blur)[0]\n",
    "\n",
    "weights = torch.clip(-torch.log(s_mask), 0, 10)\n",
    "final_blur = sil_blur * weights\n",
    "\n",
    "plot_images(\n",
    "    [\n",
    "        sketch,\n",
    "        normal,\n",
    "        silhouette,\n",
    "        silhouette + surface_mask * 2,\n",
    "        sil,\n",
    "        sil_blur,\n",
    "        sil_blur + surface_mask * 2,\n",
    "        final_blur,\n",
    "        final_blur + surface_mask * 2,\n",
    "    ],\n",
    "    size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neg Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10, 4112, (4117), 12, 13, 4152\n",
    "# obj_label = 4117\n",
    "# obj_label = 4152\n",
    "obj_label = 4016\n",
    "min_eps = 1e-06\n",
    "max_eps = 1e-03\n",
    "azim = 30\n",
    "elev = -20\n",
    "width = 256\n",
    "height = 256\n",
    "focal = 512\n",
    "\n",
    "# get the sketch form the dataset\n",
    "img = metainfo.load_sketch(metainfo.obj_ids[obj_label], \"00011\")\n",
    "sketch = trans(img)[None, ...].to(\"cuda\")\n",
    "\n",
    "# get the rendered normal\n",
    "model.latent = model.loss.embedding(sketch, mode=\"sketch\")[0]\n",
    "model.deepsdf.hparams[\"surface_eps\"] = min_eps\n",
    "model.deepsdf.create_camera(azim=azim, elev=elev)\n",
    "model.deepsdf.eval()\n",
    "with torch.no_grad():\n",
    "    points, surface_mask = model.deepsdf.sphere_tracing(\n",
    "        latent=model.latent,\n",
    "        points=model.deepsdf.camera_points,\n",
    "        mask=model.deepsdf.camera_mask,\n",
    "        rays=model.deepsdf.camera_rays,\n",
    "    )\n",
    "    image = model.deepsdf.render_grayscale(\n",
    "        points=points,\n",
    "        latent=model.latent,\n",
    "        mask=surface_mask,\n",
    "    )\n",
    "rendered_normal = image.detach().cpu().numpy()\n",
    "sketch, normal = to_image(img).permute(1, 2, 0), rendered_normal\n",
    "\n",
    "normal_input = model.deepsdf.image_to_siamese(torch.tensor(normal).to(\"cuda\"))\n",
    "sketch_input = model.deepsdf.image_to_siamese(torch.tensor(sketch).to(\"cuda\"))\n",
    "normal_emb = model.loss.embedding(normal_input)\n",
    "sketch_emb = model.loss.embedding(sketch_input)\n",
    "loss = model.loss.compute(normal_emb, sketch_emb)\n",
    "print(loss)\n",
    "\n",
    "# silhouette information\n",
    "min_sdf = torch.abs(model.forward(points)).reshape(width, height).detach().cpu()\n",
    "min_points = points.reshape(width, height, 3).detach().cpu()\n",
    "min_normals = ((image - 0.5) / 0.5).detach().cpu()\n",
    "silhouette = ((min_sdf < max_eps) & (min_sdf > min_eps)).numpy().astype(np.uint8)\n",
    "\n",
    "\n",
    "surface_mask = (\n",
    "    surface_mask.reshape(width, height).detach().cpu().numpy().astype(np.uint8)\n",
    ")\n",
    "\n",
    "\n",
    "sil = torch.zeros_like(min_sdf)\n",
    "w2c = model.deepsdf.world_to_camera.detach().cpu().to(torch.float32)\n",
    "idx = np.where(silhouette)\n",
    "w_points = min_points[idx] - min_normals[idx] * min_sdf[idx][..., None]\n",
    "\n",
    "c_points = np.ones((w_points.shape[0], 4))\n",
    "c_points[:, :3] = w_points\n",
    "c_points = w2c @ c_points.T\n",
    "c_points = c_points.T\n",
    "\n",
    "pxs = ((width * 0.5) - (c_points[:, 0] * focal) / c_points[:, 2]).to(torch.int)\n",
    "pys = ((height * 0.5) - (c_points[:, 1] * focal) / c_points[:, 2]).to(torch.int)\n",
    "\n",
    "inside_mask = (pxs >= 0) & (pxs < width) & (pys >= 0) & (pys < height)\n",
    "pxs = pxs[inside_mask]\n",
    "pys = pys[inside_mask]\n",
    "\n",
    "unique_idx, counts = torch.stack([pys, pxs]).unique(dim=1, return_counts=True)\n",
    "sil[unique_idx[0], unique_idx[1]] = counts.to(torch.float32)\n",
    "\n",
    "blur = v2.GaussianBlur(kernel_size=5, sigma=3.0)\n",
    "sil_blur = blur(torch.stack([sil, sil, sil]))[0]\n",
    "sil_blur = torch.clip(sil_blur - 0.5, min=0)\n",
    "\n",
    "blur1 = v2.GaussianBlur(kernel_size=9, sigma=9)\n",
    "in_blur = torch.tensor(np.stack([surface_mask, surface_mask, surface_mask]), dtype=torch.float32)\n",
    "s_mask = blur1(in_blur)[0]\n",
    "\n",
    "weights = torch.clip(-torch.log(s_mask), 0, 10)\n",
    "final_blur = sil_blur * weights\n",
    "\n",
    "plot_images(\n",
    "    [\n",
    "        sketch,\n",
    "        normal,\n",
    "        silhouette,\n",
    "        silhouette + surface_mask * 2,\n",
    "        sil,\n",
    "        sil_blur,\n",
    "        sil_blur + surface_mask * 2,\n",
    "        final_blur,\n",
    "        final_blur + surface_mask * 2,\n",
    "    ],\n",
    "    size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sdf = torch.abs(model.forward(points))\n",
    "silhouette = min_sdf.reshape(256, 256) < model.deepsdf.hparams[\"surface_eps\"] * 50\n",
    "plt.imshow(silhouette.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sdf = torch.abs(model.forward(points))\n",
    "silhouette = min_sdf.reshape(256, 256) < model.deepsdf.hparams[\"surface_eps\"] * 10\n",
    "plt.imshow(silhouette.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normals = model.deepsdf.render_normals(points, model.latent, model.deepsdf.camera_mask)\n",
    "plot_images(normals.detach().cpu().numpy())\n",
    "normals = (normals - 0.5) * 2  # IMPORTANT transform back to normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_points = (\n",
    "    points.reshape(256, 256, 3) - normals * min_sdf.reshape(256, 256)[..., None]\n",
    ")\n",
    "(normals * min_sdf.reshape(256, 256)[..., None])[surface_mask.reshape(256, 256)]\n",
    "intrinsic = torch.tensor(\n",
    "    [\n",
    "        [512, 0, 0],\n",
    "        [0, 512, 0],\n",
    "        [0, 0, 1],\n",
    "    ]\n",
    ").to(proj_points)\n",
    "p = proj_points @ model.deepsdf.world_to_camera[:3, :3].T.float()\n",
    "# p = (p @ intrinsic.T)[:, :, :2]\n",
    "\n",
    "# i = np.zeros((256, 256))\n",
    "# for x in tqdm(range(256)):\n",
    "#     for y in range(256):\n",
    "#         px = (p[:, :, 0] >= x) & (p[:, :, 0] <= x+1)\n",
    "#         py = (p[:, :, 1] >= y) & (p[:, :, 1] <= y+1)\n",
    "#         hit = bool((px & py).sum())\n",
    "#         if hit:\n",
    "#             i[x,y] = 1.0\n",
    "\n",
    "from lib.render.camera import Camera\n",
    "\n",
    "camera = Camera()\n",
    "camera.get_camera_to_world() @ np.array([1, 0, 4, 1])\n",
    "intrinsic = np.array(\n",
    "    [\n",
    "        [512, 0, 0],\n",
    "        [0, 512, 0],\n",
    "        [0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "intrinsic @ np.array([0, 0, 4])\n",
    "256 * 0.5 - 128\n",
    "# (0 - 256 * 0.5) / 512\n",
    "# (0 - 256 * 0.5) / 512\n",
    "128 + (512 * 1) / 4, 128 + (512 * 1) / 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch2shape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
